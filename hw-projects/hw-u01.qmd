---
title: "Homework U01: Who will stay together and who will call it splits?"
author: "Derek Powell"
bibliography: ../references.bib
editor: source
---

::: {.callout-caution icon="false"}
## Learning Objectives

Our learning objectives for this homework are:

- Apply the fundamental machine learning workflow from start to finish
- Use data munging skills to conduct feature engineering for machine learning
- Gain hands-on experience with building and applying logistic regression models
- Use model visualizations to gain insight into the dynamics of romantic relationships
:::

```{r}
#| echo: false
#| message: false
library(tidyverse)
library(tidymodels)

hcmst <- read_csv("data/hcmst.csv")

```

![](../imgs/ambiguous-couple.jpeg)

Romantic relationships are central to human experience, offering deep connections, companionship, and love. Romantic relationships play a pivotal role in shaping our emotional well-being and overall life satisfaction From the exhilarating rush of falling in love to the profound impact of a break-up, the dynamic emotions, thoughts, and behaviors that characterize romantic relationships hold profound importance in people's lives, significantly influencing their overall happiness and well-being.

Research consistently shows that individuals in satisfying romantic partnerships report higher levels of life satisfaction, mental health, and physical well-being.

However, romantic relationships are not without their challenges. Break-ups, or the dissolution of romantic relationships are major life stressors that can have profound impacts on an individual's psychological and emotional state. Break-ups can lead to feelings of grief, sadness, anger, and even physical symptoms, akin to mourning the loss of a loved one.

For many people, finding and maintaining healthy romantic relationships is an essential component of their overall life fulfillment and emotional stability. So what kinds of romantic relationships remain successful? If a break-up is imminent, can it be forseen?

**In this homework, we will use machine learning to predict whether couples will remain together in 2020 based on demographic and survey information collected in 2017.**

## The data

The data for this homework comes from Stanford University's [How Couples Meet and Stay Together (HCMST) study](https://data.stanford.edu/hcmst2017). This survey features a set of 3,510 survey respondents first surveyed in 2017, who were then followed up with in 2020 (2,107 subjects) and in 2022 (1,722) subjects. We will focus on the participants who were involved in a romantic relationship in 2017 and who responded again to questions in 2020.

## Exercise 1

We want to predict which couples will stay together and which will break up, so let's load the data and see how many breakups we have in our dataset.

::: {.callout-note icon="false"}
## Exercise 1

First, load the data from `data/hcmst.csv`. Then, examine the balance of the classes (0 = broken up, 1 = together) coded by the `w2_brokeup` variable.
:::


## Exercise 2

Before we make a model, let's do some more exploratory data analysis. One variable that seems likely to be highly predictive of whether couples break up is relationship quality. This quality measure is reverse-coded, as shown in the codebook entry below (note: it has been renamed for clarity).

![](../imgs/hcmst-rel-qual-code.png)

::: {.callout-note icon="false"}
## Exercise 2

Make a plot of the **proportion** of couples who broke up by relationship quality. Then, make a plot of the **number** of couples who broke up, plotted by relationship quality. Compare and interpret the two plots. Briefly discuss what this might mean for our ability to predict breakups from just this variable.
:::


## Exercise 3

Let's zoom back out and look at all the variables present in the dataset. A few notes on the variable name formatting:

-   `id` indicates respondent id number
-   `w1_` indicates wave 1 (2017); `w2_` indicates wave 2 (2020)
-   `*_p_` indicates a value for the respondent's partner (otherwise, for the respondent)

```{r}
glimpse(hcmst)
```

All of these (except `id` and `w2_brokeup`) are variables we might use as **features** in our model. To make sure they are used appropriately, we need to pay attention to the type of feature they are. 

Some of these features are **continuous** (or at least ordered) and some are categorical (or **discrete**). Look through the list of variables and think about which might be continuous, at least in principle. Then complete the exercise below. 

::: {.callout-note icon="false"}
## Exercise 3

Modify the `hcmst` dataset to translate discrete, cateogrical predictors into `factors` and keep continuous variables left as `numeric`. Expand the hint below to see which variables should be kept `numeric`.

::: {.callout-note icon="false" collapse="true"}
## Hint
Continuous variables: `w1_age`, `w1_p_age`, `w1_yrsed`, `w1_p_yrsed`, `w1_q21a_year`, `w1_rel_qual`, `w1_sex_frequency`, `w1_polparty`, `w1_p_polparty`, `w1_fam_seen_monthly`, `w1_hh_income`, `w2_shelter_combo_months`
:::

:::

::: callout-important
This is a good place to save your notebook, render it, and confirm that it looks as you expect.
:::


## Exercise 4

Now we can begin our machine-learning workflow!

::: {.callout-note icon="false"}
## Exercise 4

Split the data into training (80%) and testing (20%) splits. Since we won't use it for prediction, drop the `id` column before making these splits. Make sure to stratify the train/test splits to ensure a representative class balance for our predictions. Call your training and testing splits `train` and `test`
:::



## Exercise 5

::: {.callout-note icon="false"}
## Exercise 5

We will build several models and we'll use k-fold cross-validation to compare them. Set up cross validation with 10 folds. Remember, `tidymodels` calls this "v-fold cross validation".
:::

## Exercise 6

Let's start building our first model. Our first model will use all the available features from Wave 1 (2017) to predict breakups in Wave 2 (2020).

::: {.callout-note icon="false"}
## Exercise 6

Build a workflow to train a logistic regression model. As part of the workflow, create a recipe that selects only the Wave 1 features as predictors (and the `w2_brokeup` variable to be predicted).
:::


::: callout-important
This is a good place to save your notebook, render it, and confirm that it looks as you expect.
:::

## Exercise 7

If you examine the features we have available for prediction (e.g. see the `glimpse()` above), you should notice that some of these features seem more like basic demographics that people might happily share or that might otherwise be available, whereas other features are more intimate and personal responses given in the context of this survey.

::: {.callout-note icon="false"}
## Exercise 7

Examine the dataset and list two examples of each kind of feature.
:::

## Exercise 8

Let's start building our second "reduced" model. We'll build another model that leverages only "demographic" sorts of features from Wave 1. How well can we predict couples' breakups from the sort of information that might be publicly available or accessible?

::: {.callout-note icon="false"}
## Exercise 8

Build a recipe to create another logistic regression model that does not include any sensitive or private features. As part of the pipeline, select only the "public" or "demographic" type features. Use the list of features described in the hint below.

::: {.callout-note icon="false" collapse="true"}
## Hint
Deselect the variables for relationship quality and sex frequency.
:::

:::


## Exercise 9

Now it's time to fit our models in our cross-validation folds and evaluate their performance.

::: {.callout-note icon="false"}
## Exercise 9

Fit both models to the 10 cross-validation folds.
:::


## Exercise 10

::: {.callout-note icon="false"}
## Exercise 10

Compare the accuracy of these two models. What do you make of those findings? Now compare the AUC for the two models, what do you make of these differences? What explains the difference or similarity?
:::



## Exercise 11

Finally, let's close by training a final model and testing its performance on the test set. Typically, we would pick the best model based on its cross validation performance. But here, let's consider our ability to predict with "public" data. 

::: {.callout-note icon="false"}
## Exercise 11

Retrain the model with only "public" features on the full training data set.
:::

## Exercise 12

::: {.callout-note icon="false"}
## Exercise 12

Use the final model to generate predictions for the testing data (accuracy and AUC) and create a confusion matrix to show the proportions of true and false positive and negative cases. Examine at the help of `?metrics` for guidance on computing AUC (and use `.pred_0` as the class probability variable).

Consider what sort of usefulness the model might have, given its predictive performance. Are there applications where it might be put to use (for good or ill)? Write a paragraph or so on your thoughts.
:::



::: callout-important
This is a good place to save your notebook, render it, and confirm that it looks as you expect.
:::

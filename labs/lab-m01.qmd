---
title: "Module 1 Lab: Election Forcasting"
author: "Derek Powell"
format: 
  html:
    embed-resources: true
editor: visual
theme: cosmo
---

::: {.callout-caution icon="false"}
## Learning Objectives

Our learning objectives for this module are:

-   Introduce foundational frameworks and processes of machine learning
-   Introduce "splitting" data into training and test splits
-   Demonstrate use of linear regression in `tidymodels`
:::

Elections are important! More about this blah blah.

## Data

We will use data on U.S. House of Representatives Congressional Elections in 2014, 2016, 2018, and 2020. 

```{r}
#| message = FALSE
library(tidyverse)
library(tidymodels)
library(broom)

congress <- read_csv("../data/congress.csv")
```


# Exercises

We're going to start by predicting election results in 2018 from the results the prior election in 2016. 

Before we can really begin that though, we need to do some ... drum roll please ... you guessed it! Data Munging!

Our first step will be to set up our data so we can build our models. For each district, we will try to predict the share of votes won by the democratic House candidate. The first and most important predictor will be the democratic vote share from the prior election. Another helpful predictor could be whether or not the candidate is an incumbent. 

In American politics, there is a well-known incumbeny advantage---incumbents tend to be favored in elections. There are lots of reasons for this, but at very least they have automatic name recognition and the station of the office with which to represent themselves. And, if things are generally going reasonably well, they have the baseline credibility of having the keys to the Capitol without burning it down.

::: {.callout-note icon="false"}
## Exercise 1

Take the `df` data, add a variable called `incumbent` that indicate whether the candidate is an incumbent or not.

::: {.callout-note icon="false" collapse="true"}
## Hint

There is more than one way to do this, but you will likely want to make use of `group_by()` and a function that might be new called `lag()`. The help can help!
:::

:::

```{r}
df <- congress %>% 
  arrange(year) %>% 
  group_by(candidate) %>% 
  mutate(
    incumbent = if_else(lag(winner)==1, 1, 0, missing=0),
    incumbent = if_else(year==2014, NA, incumbent)
    )
```


::: {.callout-note icon="false"}
## Exercise 2

Now, do some further  data munging of the sort we learned last semester.

1. Filter `df` to include only the rows for Democrat and Republican candidates
2. Pivot the data to a wide format, so that for each Congressional district we have variables  representing the proportion of democratic votes in 2016 and 2018, and whether or not there was a democrat incumbent going into the 2018 election. If there is more than one D or R candidate, use the proportion value for the candidate with the most votes.
3. Replace `NA` values for vote proportion and incumbency with zero---if there's not value it's because no one ran and therefore they got zero votes.
:::

```{r}
df <- df %>% 
  ungroup() %>% 
  # filter(year %in% c(2014, 2016, 2018), party %in% c("D","R")) %>%
  group_by(year, district) %>% 
  select(year, state, district, party, prop, incumbent) %>%
  pivot_wider(
    id_cols = c(state, district), 
    names_from = c(party, year), 
    values_from = c(prop, incumbent), 
    values_fn = max
    ) %>% 
  replace(is.na(.), 0)
  
```


With our data ready in our `df` tibble, we can start building a model! Before we do that though, we need to split our data into training and testing splits. We can use the classic 80% for training and 20% for testing.

::: {.callout-note icon="false"}
## Exercise 3

Using `tidymodels`, split the data into training and testing splits called `train` and `test`.

:::

```{r}
set.seed(42)
df_split <- initial_split(df)
df_split
```

```{r}
train <- training(df_split)
test <- testing(df_split)
```


Now we'll build our model specification and modeling workflow.

::: {.callout-note icon="false"}
## Exercise 4

Create a model specification for linear regression and call it `linear_spec`.

:::

```{r}
linear_spec <- linear_reg()
```


::: {.callout-note icon="false"}
## Exercise 4

Create a workflow for our model with the appropriate formula to predict the proportion of democratic votes in 2018 from the proportion in 2016. Call it `lin_wflow1`.

:::

```{r}
lin_wflow1 <- workflow(prop_D_2018 ~ prop_D_2016) %>% 
  add_model(linear_spec)
  
```

::: {.callout-note icon="false"}
## Exercise 5

Now fit the model to the `train` data (finally!). Call this `lin_fit1`.

:::


```{r}
lin_fit1 <- lin_wflow1 %>% 
  fit(data = train)
```

Now check the fit on the training data

::: {.callout-note icon="false"}
## Exercise 5

Let's look at this two ways, by some metrics, including the Root Mean Squared Error and Mean Absolute Error (MAE) and by plotting the predicted values against the actual observed values.

:::

```{r}
lin_fit1 %>% 
  augment(train) %>% 
  metrics(prop_D_2018, .pred)

lin_fit1 %>% 
  augment(train) %>% 
  ggplot(aes(x = .pred, y = prop_D_2018)) +
  geom_point() +
  theme(aspect.ratio = 1)
```

By looking at the predictions against the actual election results, we can see our model's performane is somewhat mixed! Specifically, there are some elections that seem to be predicted quite well (the "cloud" of points along the 1:1 line), but others that are not (those kind of along the edges of the plot). What do you think is going on with the elections the model is failing to predict well?

::: {.callout-note icon="false"}
## Exercise 6

Let's inspect the model's coefficients and see if they offer any clues. Use the `tidy()` function from the `broom` package. What does the intercept represent? Can you see that reflected on the plot above anywhere? Think about this a bit before moving on to the next exercise to see if you can come up with a theory for what is happening. When you've thought it through, you can expand the explanation below.

::: {.callout-warning icon="false" collapse = "true"}
## Explanation

Of course the intercept represents the predicted value when all predictors are zero. We can see a vertical line of points at about exactly that spot---so that's a clue there are actually data points in our data with a proportion of zero. These are *uncontested* elections where there was no Democratic party candidate. 

But whenever a candidate actually runs, they do so because they expect to get at least some share of the vote---more than 21\% at least.

:::

:::

```{r}
tidy(lin_fit1)
```

We'd like to add a predictor to our dataset to account for this in our model. But, if we are going to add a predictor we will need to add it to our train and test splits. A better way to manage this kind of "feature engineering" is to use a **recipe**.

::: {.callout-note icon="false"}
## Exercise 7

Create a new workflow `lin_wflow2` that adds a `step_mutate()` to add a recipe step creating a new variable called `uncontested_2016` that is `1` if the democratic vote share was 0 in 2016 and `0` otherwise. Make sure the workflow applies a new formula that uses this variable in the linear regression model.

Then, fit this new model and call it `lin_fit2`

:::

```{r}
## not sure how recipes work :(
rec <- recipe(prop_D_2018 ~ prop_D_2016 + uncontested_2016, data = train) %>% 
  step_mutate(uncontested_2016 = if_else(prop_D_2016 == 0, 1, 0))

lin_wflow2 <- workflow() %>% 
  add_formula(prop_D_2018 ~ prop_D_2016 + uncontested_2016) %>% 
  add_recipe(rec) %>% 
  # step_mutate(uncontested_2016 = if_else(prop_D_2016 == 0, 1, 0)) %>% 
  add_model(linear_spec)

lin_fit2 <- lin_wflow2 %>% 
  fit(data = train)
```


Now let's try creating some new model specifications that use more predictors.

::: {.callout-note icon="false"}
## Exercise 6

Create a new workflow specification adding the vote share from 2014 to the formula (`lin_wflow2`) and another further adding whether or not the candidate was an incumbent in 2018 (`lin_wflow3`). Fit both of these to the training data.

:::


```{r}

```

::: {.callout-note icon="false"}
## Exercise 7

Compute prediction metrics for each of the model workflows on the training data. Which would you pick based on these?

:::

```{r}

```


Now we can look at the test data and see which did better.

< exercise >


But wait, how would we actually use data like this? Let's take ourselves back to 2019---the federal government was shutting down, Felicity Huffman was in prison, "Old Town Road" was blaring everywhere, and an intrepid data scientist like yourself might be looking to forecast the likely results of the 2020 U.S. House election. Perhaps such a budding Nate Silver could use a model like the one we just created to do just that: using a forecasting model built from 2016 data to forecast by predicting from the 2018 data.


< exercise >


Can use our model to predict the total number of house seats too.

< exercise >

This would be more useful with a measure of uncertainty---perhaps we'll get to something like that later.


------------------------------------------------------------------------

## Quarto information

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>

### Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

### Additional formatting

Quarto includes "callouts," including: `note`, `tip`, `warning`, `caution`, and `important`. I think it will be useful to use a few of these in formulaic ways. We can use these however by defining a custom title and suppressing the icons where relevant

Let's use the "note" callout for the lab exercises. We can provide our own more informative titles as needed with `##` level headings inside the note as desired. If we like, we can also emd another "hint" callout and collapse them with `collapse=true`.

::: {.callout-note icon="false"}
## Exercise 1

Do something involving making a machine learning model, probably!

::: {.callout-note icon="false" collapse="true"}
## Hint

This would be helpful though.
:::
:::

Let's override the icon of the caution callout with `icon=false` for "learning objectives" to start the document.

::: {.callout-caution icon="false"}
## Learning Objectives

Our learning objectives for this module are:

-   Introduce foundational frameworks and processes of machine learning
-   Introduce "splitting" data into training and test splits
-   Demonstrate use of linear regression in `tidymodels`
:::

::: callout-tip
And one for tips and tricks etc.
:::

::: callout-important
And this important one for things we really want to flag. Probably use this mostly for instructions regarding saving, formatting. and submitting assignments.
:::

::: column-margin
We can also use the `.column-margin` div to include any kinds of marginal comments, brief tips/tricks, etc.
:::

### Other Quarto Resources

Some things that look really useful for us:

-   [Diagrams guide](https://quarto.org/docs/authoring/diagrams.html)
-   [Code annotation syntax guide](https://quarto.org/docs/authoring/code-annotation.html)
-   [Embedding Videos](https://quarto.org/docs/authoring/videos.html)

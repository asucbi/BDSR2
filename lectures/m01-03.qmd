---
title: "Machine Learning: The Workflow"
subtitle: Behavioral Data Science in R II
format: 
  revealjs:
    css: style.css
bibliography: ../references.bib
---
```{r}
#| include: false

library(tidyverse)
```


## Machine learning: The basic idea 

::: {.center}
```{mermaid}
%%| fig-width: 9.5
flowchart LR
  A[(Data)] -- used to make --> B[Model] -- used to make --> C{{Predictions}}
```
:::

## Test data

Beginning at the end:

::: {.incremental}
- We want to make prediction for ***new*** data. 
- To know whether our predictions will be good, need to test our models on ***new*** data
  - Not the same data that was used to make the model!
:::

## Splitting the ~~baby~~ data

:::: {.columns}

::: {.column width="50%"}

We split our data into training and testing splits:

:::

::: {.column width="50%"}

```{r}
#| echo: false
#| fig-height: 3

tibble(
  Split = ordered(c("Train", "Test"), levels = c("Train", "Test")),
  prop = c(.80, .20)
) %>% 
  ggplot(aes(x=-prop, y = "", fill = Split)) +
  geom_bar(stat="identity") +
  scale_fill_discrete() +
  theme_minimal(base_size = 18) +
  theme(
    legend.position = "top",
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank(),
    aspect.ratio = 1/3
    )
  
```
:::

::::

Using some for **Training** and some for **Testing**:

```{mermaid}
%%{init: {"flowchart": {"htmlLabels": false}} }%%
graph LR
  d[(Data)] --> split([Split]) --> trainSplit[(Training)]
  split --> testSplit[(Testing)]
  trainSplit --> model[Model]
  model --> val{{Final Validation}}
  testSplit  ---> val
  
```

## Machine learning: Making good model(s)


:::: {.columns}

::: {.column width="50%"}

- Building the best model often means making many models and picking the best one
- Remember: ***Best*** meaning best at predicting for ***new*** data

::: {.fragment}
Whatever data we use to pick the model won't be new data!
:::

:::

::: {.column width="50%"}


```{mermaid}
%%| fig-width: 4.5
graph LR
  trainSplit[(Training)] --> m1[Model 1] & m2[Model 2] & m3[...] & m4[Model j]
  
  m1 & m2 & m3 & m4 --> sel{{Model selection}}

```

:::

::::



## Validation data

One solution: create another ***validation*** split of data.

```{r}
#| echo: false
#| fig-height: 3

tibble(
  Split = ordered(c("Train", "Test", "Validation"), levels = c("Train", "Validation", "Test")),
  prop = c(.6, .2, .2)
) %>% 
  ggplot(aes(x=-prop, y = "", fill = Split)) +
  geom_bar(stat="identity") +
  scale_fill_discrete() +
  theme_minimal(base_size = 18) +
  theme(
    legend.position = "top",
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank(),
    aspect.ratio = 1/3
    )
  
```
- ***Train*** models on the [training data]{.text-red}
- ***Compare*** and select best model using the [validation data]{.text-green}
- ***Predict*** future model performance using the [test data]{.text-blue}

## Data Budget

::: {.callout-note}
## Think about it ...
Aren't we going to start running out of data?
:::

::: {.incremental}
- More training data $\rightarrow$ better models
- More validation/testing data $\rightarrow$ more accurate validation
::: 

::: {.fragment}
How can we use as much data as possible to get the best models and evaluations?
::: 

## Cross Validation

```{r}
library(patchwork)

col_ <- function(x, nrow, ncol){
  col <- floor((x-1)/ncol) + 1
  return(col)
}

row_ <- function(x, nrow, ncol){
  return( -1*((x-1) - nrow*col_(x, nrow, ncol) + 1 ) )
}

ids <- seq(1,25,1)
shuffled_ids <- dplyr::row_number(runif(25))

## make 5 copies
expand_grid(
  id = ids,
  fold = c(1,2,3,4,5)
) %>% 
  group_by(fold) %>% 
  mutate(
    order_id = id,
    row = -row_(order_id, 5, 5),
    col = -col_(order_id, 5, 5),
    # Split = if_else(-col==fold, "Validation", "Train"),
    fold = paste("Fold", fold)
    ) %>% 
  ggplot(aes(x = row, y = col, label = id)) +
  geom_tile(fill = "lightgrey", color = "black") +
  geom_text(size=3) +
  facet_wrap(~fold, nrow = 1) +
  # scale_fill_manual(values = c("lightyellow", "lightblue")) +
  theme_minimal() +
  theme(
    aspect.ratio=1,
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank()
    ) +
  labs(title = "Make k copies of the data") +

## Randomize ...
expand_grid(
  id = ids,
  fold = c(1,2,3,4,5)
) %>% 
  group_by(fold) %>% 
  mutate(
    order_id = shuffled_ids,
    row = -row_(order_id, 5, 5),
    col = -col_(order_id, 5, 5),
    # Split = if_else(-col==fold, "Validation", "Train"),
    fold = paste("Fold", fold)
    ) %>% 
  ggplot(aes(x = row, y = col, label = id)) +
  geom_tile(fill = "lightgrey", color = "black") +
  geom_text(size=3) +
  facet_wrap(~fold, nrow = 1) +
  # scale_fill_manual(values = c("lightyellow", "lightblue")) +
  theme_minimal() +
  theme(
    aspect.ratio=1,
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank()
    ) +
  labs(title = "Randomize ...") +

## ... and assign to train and test splits
expand_grid(
  id = ids,
  fold = c(1,2,3,4,5)
) %>% 
  group_by(fold) %>% 
  mutate(
    order_id = shuffled_ids,
    row = -row_(order_id, 5, 5),
    col = -col_(order_id, 5, 5),
    Split = if_else(-col==fold, "Validation", "Train"),
    fold = paste("Fold", fold)
    ) %>% 
  ggplot(aes(x = row, y = col, label = id)) +
  geom_tile(aes(fill=Split), color = "black") +
  geom_text(size=3) +
  facet_wrap(~fold, nrow = 1) +
  scale_fill_manual(values = c("lightyellow", "lightblue")) +
  theme_minimal() +
  theme(
    aspect.ratio=1,
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank()
    ) +
  labs(title = "... and assign to train and test splits") +
  plot_layout(ncol = 1)
  
```


## Cross Validation workflow

```{mermaid}
%%{init: {"flowchart": {"htmlLabels": false}} }%%
graph LR
  trainSplit[(Training)] --> resamp([Resampling])
  resamp --> m1 & m2 & m3 & m4
  
  subgraph K-folds
  m1[Model 1] & m2[Model 2] & m3[...] & m4[Model j]
  end

  m1 & m2 & m3 & m4 --> sel{{Model selection}}

```

## The overall machine learning workflow

```{mermaid}
%%| fig-width: 10
%%{init: {"flowchart": {"htmlLabels": false}} }%%
graph LR
  d[(Data)] --> split([Split]) --> trainSplit[(Training)]
  split --> testSplit[(Testing)]
  trainSplit --> resamp([Resampling])
  resamp --> m1 & m2 & m3 & m4
  
  subgraph K-folds
  m1[Model 1] & m2[Model 2] & m3[...] & m4[Model j]
  end

  m1 & m2 & m3 & m4 --> sel{{Model selection}}
  sel --> final[Final Model]
  trainSplit --> final
  final --> val{{Final Validation}}
  testSplit ------> val
  
  
```

## Before the workflow

- Data acquisition
- Data preprocessing + cleaning
- Domain understanding
- Exploratory data analysis + visualization

::: {.fragment}
[***AKA: Data Science!***]{.text-red}
:::

## After the workflow

:::: {.columns}

::: {.column width="50%"}

### Practical Implementation

- Efficiency
- Performance Monitoring
- Model updating and refinement

:::

::: {.column width="50%"}

### Insight and inference

- Feature importance
- Visualization and insights

:::

::::


# Implementing the workflow in `tidymodels`

## A case study: Taxi tips

## Splitting data into training and testing splits

## Setting up Cross Validation

## Fitting models and selecting the best

## Validating on the test data



---

## Bullets

When you click the **Render** button a document will be generated that includes:

-   Content authored with markdown
-   Output from executable code

## Code

When you click the **Render** button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r echo=TRUE}
1 + 1
```


## Column formatting

Machine learning can be applied to tackle many different kinds of problems, including:

:::: {.columns}

::: {.column width="50%"}

**Supervised learning**

- Prediction
- Classification

:::

::: {.column width="50%"}


**Unsupervised learning**

- Clustering

:::

::::


## Figure Layouts

:::: {.columns .v-center-container}

::: {.column width="50%"}
Machine learning can be applied to many different kinds of data, including:

- text
- audio
- images
- video
- tabular data (e.g. survey data)
:::

::: {.column width="50%"}

::: {layout-nrow=2}

![Audio](../imgs/audio-spectrogram.png)

![Images](../imgs/MnistExamplesWikipedia.png)

![Text](../imgs/bigdatawordcloud.jpeg)

![Tabular](../imgs/tabulardata.png)

:::

:::

::::

## CSS

See `style.css` for custom formatting options.

## Other formatting

::: callout-tip
Callouts work the same as for non-presentation documents. I don't think margin notes can be used though.
:::

## Citations

You can use pandoc citation style to add citations. Let's use the convention: `[@author1.author2YEAR]` and `[@author.etalYEAR]` A bibliography is automatically created.

I've started off the references with our main text [@gareth.etal2014]. 

---

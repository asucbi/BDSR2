---
title: "Logistic Regression in Practice"
subtitle: Behavioral Data Science in R II
format: 
  revealjs:
    css: style.css
execute:
  echo: true
bibliography: ../references.bib
---


## Example: Wells in Bangladesh

![](../imgs/bangladeshi-wells-guardian.png){fig-align="center"}


## Arsenic in well water

::: {style="font-size: 65%;"}
- Millions of people in Bangladesh get their water from hand-pumped tube wells
- A screening of 5 million wells from 2000 to 2003 found that wells of an estimated 20 million people had unsafe levels of arsenic (above 50 micrograms per liter)
- More recent screenings suggest that the government's efforts have failed to address this problem
:::

::: {layout-ncol=2}
![](../imgs/Bangla-map-contam-wells-HRW.jpg)

![](../imgs/BangladeshArsenic_6_254.jpg)
:::

## Arsenic poisoning symptoms

![](../imgs/arsenic-symptoms.png){fig-align="center"}

::: {.hidden}
- Short-term symptoms:
  - Flu-like symptoms, shortness of breath, numbness
  - Warts and lesions, hardening of skin, chronic sore throat and digestive issues
- Long-term symtoms:
  - Increased risk for liver, heart, bladder disease
  - Neurotoxicity and neurosystem complications
  - Increased risk for many cancers
:::

## Health decision-making: Switching wells

::: {style="font-size: 80%;"}


:::: {.columns}
::: {.column width="50%"}
- The Bangladeshi water system is highly distibuted, each well serves on average 11 people
- Even though your well is unsafe, a neighbor's well may be safe
- @gelman.etal2004 analyzed a survey of users of several thousand wells to examine people's decision-making: when will people with unsafe wells switch to using another neighbor's well?

:::
::: {.column width="50%"}

**Map of wells surveyed**

![](../imgs/bangladeshi-well-map.png)
:::
::::

:::

## The `wells` data

```{r}
#| include: false
library(tidyverse)
library(tidymodels)
library(broom)
```


```{r}
#| echo: true
library(rosdata)

data(wells)

wells <- as_tibble(wells) %>% 
  mutate(switch = factor(if_else(switch == 1, "Yes", "No")))

wells
```

## Exploratory Data Analysis

```{r}
#| echo: true
wells %>% 
  count(switch) %>% 
  mutate(prop = n/sum(n))
```

## EDA: Boxplot visualization

::: {.panel-tabset}

## Code

```{r}
#| echo: true
arsenic_dist100_plt <- wells %>%
  pivot_longer(cols = c(arsenic, dist100), names_to = "var", values_to = "val") %>% 
  ggplot(aes(x = switch, y = val)) +
  geom_boxplot() +
  facet_wrap(~var, scales = "free_y")
```

## Plot

```{r}
#| echo: false
arsenic_dist100_plt
```

:::


## EDA: Binned obs. visualization
::: {.panel-tabset}

## Code
```{r}
#| echo: true
arsenic_switching_plt <- wells %>%
  mutate(
    arsenic_bin = cut(percent_rank(arsenic), 20),
  ) %>% 
  group_by(arsenic_bin) %>% 
  mutate(arsenic_bin_x = mean(arsenic)) %>% 
  group_by(arsenic_bin, arsenic_bin_x) %>% 
  summarize(prop = mean(switch=="Yes"), cnt = n()) %>% 
  mutate(se = sqrt(prop*(1-prop)/cnt)) %>%
  ggplot(aes(x = arsenic_bin_x, y = prop, ymin = prop - 2*se, ymax = prop + 2*se)) +
  geom_point() +
  geom_line() +
  geom_ribbon(alpha = .25) +
  labs(x = "Arsenic Bin Avg.",  y = "Prop. switched", 
       title = "Proportion switching across binned levels of arsenic",
       subtitle = "with 95% confidence intervals")
```

## Plot

```{r}
#| echo: false
arsenic_switching_plt
```

:::

## Modeling Setup

```{r}
#| echo: true
set.seed(1234)
splits <- initial_split(wells, prop =.85, strata = switch)

train <- training(splits)
test <- testing(splits)
```


## Simple logistic regression model

```{r}
#| echo: true
lr_wflow1 <- workflow() %>%
  add_formula(switch ~ arsenic) %>% 
  add_model(logistic_reg())

lr_fit1 <- fit(lr_wflow1, data = train)

```

## Evaluating the simple model

```{r}
metrics_unbalanced <- metric_set(accuracy, bal_accuracy)

lr_fit1 %>% 
  augment(test) %>% 
  metrics_unbalanced(truth = switch, estimate = .pred_class)
```


## Metrics: Accuracy

$$\text{accuracy} = \frac{\text{correct predictions}}{\text{total predictions}}$$

```{r}
#| echo: true
lr_fit1 %>% 
  augment(test) %>% 
  summarize(acc = sum(.pred_class == switch)/n())
```

## Confusion Matrix

```{r}
#| echo: false
tibble(
  actual = factor(c("+", "-", "+", "-"), ordered = TRUE, levels = c("+", "-")),
  predicted = factor(c("+", "-", "-", "+")),
  label = c("True Positive", "True Negative", "False Negative", "False Positive")
) %>% 
  ggplot(aes(x=actual, y = predicted, label = label)) +
  geom_tile(fill = "white", color = "black") +
  geom_text(size = 9) +
  theme_minimal(base_size = 24) +
  theme(
    panel.grid = element_blank(),
    ) +
  labs(x = "Actual", y = "Predicted") +
  scale_x_discrete(position = "top") 
  
```

## Metrics: TPR and TNR

::: {style="font-size: 65%;"}

**Manual calculation**

```{r}
lr_fit1 %>% 
  augment(test) %>% 
  summarize(
    acc = sum(.pred_class == switch)/n(),
    TP = sum(.pred_class == "Yes" & switch == "Yes")/sum(switch == "Yes") ,
    TN = sum(.pred_class == "No" & switch == "No")/sum(switch == "No") ,
    )
```

**`tidymodels` calculation**

```{r}
class_metrics <- metric_set(accuracy, bal_accuracy, sensitivity, specificity)

lr_fit1 %>% 
  augment(test) %>% 
  class_metrics(switch, estimate = .pred_class, event_level = "second") 
```
:::


## Metrics: Balanced accuracy

$$\text{balanced accuracy} = \frac{\text{TPR} + \text{TNR}}{2}$$

::: {style="font-size: 50%;"}


**Manual calculation**
```{r}
lr_fit1 %>% 
  augment(test) %>% 
  summarize(
    acc = sum(.pred_class == switch)/n(),
    TP = sum(.pred_class == "Yes" & switch == "Yes")/sum(switch == "Yes") ,
    TN = sum(.pred_class == "No" & switch == "No")/sum(switch == "No") ,
    bal_acc = (TP + TN)/2
    )
```

**`tidymodels` calculation**

```{r}
class_metrics <- metric_set(accuracy, sensitivity, specificity, bal_accuracy)

lr_fit1 %>% 
  augment(test) %>% 
  class_metrics(switch, estimate = .pred_class, event_level = "second") 
```
:::


## Interpreting model coefficients

```{r}
#| echo: true

tidy(lr_fit1)
```

- A 1 point increase in `arsenic` (i.e. 100 $\mu g/L$) increases the log-odds of switching by `.38`
- Makes the odds of switching `exp(.38)` = `r round(exp(.38378), 3)` **times greater**

## Plotting model predictions

```{r}
#| echo: false
lr_fit1 %>% 
  augment(
    tibble(arsenic = seq(min(train$arsenic), max(train$arsenic), .1))
  ) %>% 
  ggplot(aes(x = arsenic, y=.pred_Yes)) +
  geom_line(color = "blue") +
  geom_point(data = train, aes( x = arsenic, y = as.numeric(switch=="Yes")), position = position_jitter(height = .075, seed = .42), alpha = .1)
```


## Adding predictors

::: {style="font-size: 80%;"}

```{r}
#| echo: true
lr_wflow2 <- workflow() %>%
  add_formula(switch ~ arsenic + dist100) %>% 
  add_model(logistic_reg())

lr_fit2 <- fit(lr_wflow2, data = train)

tidy(lr_fit2)
```
:::

:::: {.columns}
::: {.column width="50%"}

::: {.callout-note icon="false"}
## Think about it ...
How would you interpret the coefficients for `arsenic` and `dist100`?
:::
:::
::: {.column width="50%"}

::: {style="font-size: 65%;"}
::: {.fragment}
- As arsenic increases, $p(switching)$ increases, as distance increases, $p(switching)$ decreases
- An increase in 100m distance reduces log-odds by .863 or **multiplies odds** by `exp(-.863)` = `r round(exp(-.328),3)`
:::

:::

:::
::::




## Interpreting predicted probabilities

::: {style="font-size: 65%;"}

```{r}
#| echo: true
ex_data <- crossing(
      arsenic =  quantile(train$arsenic, c(.1, .5, .9)),
      dist100 = quantile(train$dist100, c(.1, .5, .9))
    )

augment(lr_fit2, ex_data)

```
Comparing extremes (90th vs 10th percentile) for $p(switch)$:

- Extreme `arsenic` difference at median `dist100` $\rightarrow .758 - .488 = .270$
- Extreme `dist100` difference at median `arsenic` $\rightarrow .434 - .618 = -.184$

:::

## Standardizing predictors

```{r}
#| echo: true
#| code-line-numbers: "|1-2|5"
stdize_rec <- recipe(switch ~ arsenic + dist100, train) %>% 
  step_normalize(all_numeric_predictors())

lr_wflow2 <- workflow() %>%
  add_recipe(stdize_rec) %>% 
  add_model(logistic_reg())

lr_fit2 <- fit(lr_wflow2, data = train)

tidy(lr_fit2)
```

After standardizing, we can see that `arsenic` is actually a more important predictor

## Feature Engineering

```{r}
#| echo: false
x <- train %>%
  mutate(
    arsenic_bin = cut(percent_rank(arsenic), 20),
  ) %>% 
  group_by(arsenic_bin) %>% 
  mutate(arsenic_bin_x = mean(arsenic)) %>% 
  group_by(arsenic_bin, arsenic_bin_x) %>% 
  summarize(prop = mean(switch=="Yes"), cnt = n()) %>% 
  mutate(se = sqrt(prop*(1-prop)/cnt))

lr_fit1 %>% 
  augment(
    tibble(arsenic = seq(min(train$arsenic), max(train$arsenic), .1))
  ) %>% 
  ggplot(aes(x = arsenic, y=.pred_Yes)) +
  geom_line(color = "blue") +
  geom_point(data = train, aes( x = arsenic, y = as.numeric(switch=="Yes")), position = position_jitter(height = .075, seed = .42), alpha = .1) +
  geom_line(data = x, aes(x = arsenic_bin_x, y = prop, ymin = prop - 2*se, ymax = prop + 2*se), linetype = "dashed") +
  geom_ribbon(data = x, aes(x = arsenic_bin_x, y = prop, ymin = prop - 2*se, ymax = prop + 2*se), alpha = .25) +
  xlim(0, 6)
```


## Feature Engineering II

```{r}
#| echo: false
lr_fe <- recipe(switch ~ arsenic, train) %>%
  step_mutate(low_arsenic = if_else(arsenic < .6, "negligible", "noticeable"))
  
lr_wflow1b <- workflow() %>%
  add_recipe(lr_fe) %>%
  add_model(logistic_reg())

lr_fit1b <- fit(lr_wflow1b, data = train)
```

```{r}
#| message: false
#| warning: false 
#| echo: false
x <- train %>%
  mutate(
    arsenic_bin = cut(percent_rank(arsenic), 20),
  ) %>% 
  group_by(arsenic_bin) %>% 
  mutate(arsenic_bin_x = mean(arsenic)) %>% 
  group_by(arsenic_bin, arsenic_bin_x) %>% 
  summarize(prop = mean(switch=="Yes"), cnt = n()) %>% 
  mutate(se = sqrt(prop*(1-prop)/cnt))

lr_fit1b %>% 
  augment(
    tibble(arsenic = seq(min(train$arsenic), max(train$arsenic), .1))
  ) %>% 
  ggplot(aes(x = arsenic, y=.pred_Yes)) +
  geom_line(color = "blue") +
  geom_point(data = train, aes( x = arsenic, y = as.numeric(switch=="Yes")), position = position_jitter(height = .075, seed = .42), alpha = .1) +
  geom_line(data = x, aes(x = arsenic_bin_x, y = prop, ymin = prop - 2*se, ymax = prop + 2*se), linetype = "dashed") +
  geom_ribbon(data = x, aes(x = arsenic_bin_x, y = prop, ymin = prop - 2*se, ymax = prop + 2*se), alpha = .25) +
  xlim(0, 6)
```

## A more complex model

```{r}
#| echo: true
#| code-line-numbers: "|2|3-6"
lr_rec <- recipe(switch ~ dist100 + arsenic + educ4, train) %>%
  step_interact(~all_predictors():all_predictors()) %>%
  step_mutate(
    low_arsenic = if_else(arsenic < .6, "negligible", "noticeable"),
    no_educ = if_else(educ4 == 0, 1, 0)
    )
  
lr_wflow3 <- workflow() %>%
  add_recipe(lr_rec) %>%
  add_model(logistic_reg())

lr_fit3 <- fit(lr_wflow3, data = train)
```

## Setting up $k$-fold cross validation

```{r}
set.seed(1234)
folds <- vfold_cv(train, v = 10, strata = switch)
```

## Applying $k$-fold cross validation

::: {.panel-tabset}

## Setup
```{r}
#| code-line-numbers: "|1-5|7-12"
wflows <- as_workflow_set(
  simple = lr_wflow1, 
  two_pred = lr_wflow2, 
  complex = lr_wflow3
  )

cv_res <- workflow_map(
  wflows, 
  fn = "fit_resamples", 
  resamples = folds, 
  metrics = metric_set(accuracy, bal_accuracy)
  )
```

## Results

::: {style="font-size: 80%;"}
```{r}
collect_metrics(cv_res)
```
:::

:::

# tidymodels vs `glm()`

## Comparison with `glm()`
::: {style="font-size: 80%;"}

**`tidymodels`**

```{r}
lr_rec <- recipe(switch ~ dist100 + arsenic + educ4, train) %>%
  step_interact(~ all_predictors():all_predictors()) %>%
  step_mutate(
    low_arsenic = if_else(arsenic < .6, "negligible", "noticeable"),
    no_educ = if_else(educ4 == 0, 1, 0)
  )

lr_wflow3 <- workflow() %>%
  add_recipe(lr_rec) %>%
  add_model(logistic_reg())

fit_tm <- fit(lr_wflow3, data = train)
```

**`glm()`**

```{r}
fit_glm <- glm(
  switch ~ dist100 * arsenic * educ4 + no_educ + low_arsenic,
  family = "binomial",
  data = train %>% mutate(
    no_educ = if_else(educ4 == 0, 1, 0),
    low_arsenic = if_else(arsenic < .6, "negligible", "noticeable")
  )
)
```
:::


## References

- Reporting from *The Guardian*: [https://www.theguardian.com/global-development/2016/apr/06/millions-of-people-in-bangladesh-still-drinking-arsenic-laced-water](https://www.theguardian.com/global-development/2016/apr/06/millions-of-people-in-bangladesh-still-drinking-arsenic-laced-water)
- Reporting from *Human Rights Watch*: [https://www.hrw.org/news/2016/04/06/bangladesh-20-million-drink-arsenic-laced-water](https://www.hrw.org/news/2016/04/06/bangladesh-20-million-drink-arsenic-laced-water)